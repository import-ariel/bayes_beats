{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Some background reading and source for our data: \n",
    "https://towardsdatascience.com/how-i-built-a-lo-fi-music-web-player-with-ai-generated-tracks-36f3915e39f8/\n",
    "\"We have a couple of options when it comes to the music data format we are training the model on: raw audio, audio features (e.g. time frequency representations like Mel spectrogram), or symbolic music representation (e.g. midi files). Our goal is to generate a solo track (i.e. a sequence of notes, chords, and rests) to layer on other components like drum loops, so midi files are the easiest and most effective format to achieve our goal. Raw audio is very computationally expensive to train on.\"\n",
    "\n",
    "##### data source: https://www.kaggle.com/datasets/zakarii/lofi-hip-hop-midi/data"
   ],
   "id": "64d87e1e51fa804f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T19:20:04.391464Z",
     "start_time": "2025-05-03T19:20:04.014161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I've created a DataCleaning class to handle the data loading and cleaning process.\n",
    "# You can call on this class to load the data and clean it up as needed.\n",
    "# for example: \n",
    "\n",
    "import kagglehub\n",
    "from data.data_cleaning import DataCleaning, logger\n",
    "\n",
    "# 1) Download the dataset and grab the local folder path\n",
    "path = kagglehub.dataset_download(\"zakarii/lofi-hip-hop-midi\")\n",
    "logger.info(f\"Dataset lives at: {path}\")\n",
    "\n",
    "# 2) Point the DataCleaning class at that folder (no __main__ needed)\n",
    "cleaner = DataCleaning(midi_dir=path)\n",
    "\n",
    "# 3) Run it, capturing the in-memory objects\n",
    "encoded_seqs, sym2int, dur2int = cleaner.run(save=True)"
   ],
   "id": "b7ba019d6d48f2d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.data_cleaning:Dataset lives at: /Users/arielazria/.cache/kagglehub/datasets/zakarii/lofi-hip-hop-midi/versions/1\n",
      "INFO:data.data_cleaning:Found 93 MIDI files in /Users/arielazria/.cache/kagglehub/datasets/zakarii/lofi-hip-hop-midi/versions/1.\n",
      "Parsing MIDI files: 100%|██████████| 93/93 [00:00<00:00, 447.43it/s]\n",
      "INFO:data.data_cleaning:Parsed 93 sequences from MIDI files.\n",
      "INFO:data.data_cleaning:Built symbol vocab (258) and duration vocab (34).\n",
      "INFO:data.data_cleaning:Encoded 93 sequences.\n",
      "INFO:data.data_cleaning:Saved encoded sequences to: processed_lofi_data/encoded_sequences.json\n",
      "INFO:data.data_cleaning:Saved symbol vocabulary to: processed_lofi_data/symbol_to_int.json\n",
      "INFO:data.data_cleaning:Saved duration vocabulary to: processed_lofi_data/duration_to_int.json\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now you can use those in modeling. \n",
    "# save=False won't save the files locally"
   ],
   "id": "6f071ec08751df64",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Bayesian Env)",
   "language": "python",
   "name": "bayesian_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
